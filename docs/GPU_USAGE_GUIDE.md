# GPU/CPU Usage Guide - Sigma Analyst

## RTX 4060 8GB Optimizasyon KÄ±lavuzu

Bu kÄ±lavuz, Sigma Analyst AI Financial Analysis sisteminin RTX 4060 8GB VRAM ile optimal performans iÃ§in nasÄ±l yapÄ±landÄ±rÄ±lacaÄŸÄ±nÄ± aÃ§Ä±klar.

---

## ğŸ¯ Ã–nerilen YapÄ±landÄ±rma: HYBRID MODE

**RTX 4060 iÃ§in en iyi seÃ§enek:** `HYBRID` modu

```bash
# .env dosyasÄ±na ekleyin
COMPUTE_MODE=hybrid
```

### Hybrid Mode Nedir?

Hybrid mode, her iÅŸ tipine gÃ¶re en uygun cihazÄ± otomatik seÃ§er:

| Ä°ÅŸ Tipi | Cihaz | Neden? |
|---------|-------|--------|
| **Technical Analysis** (pandas-ta, TA-Lib) | **CPU** | NumPy/pandas CPU iÃ§in optimize edilmiÅŸ |
| **ML Tree Models** (XGBoost, LightGBM, CatBoost) | **CPU** | KÃ¼Ã§Ã¼k-orta veri setleri iÃ§in CPU daha hÄ±zlÄ± |
| **Deep Learning** (LSTM, Transformer) | **GPU** | 10-50x hÄ±z artÄ±ÅŸÄ± (RTX 4060 ile) |
| **RL Training** (PPO, Decision Transformer) | **GPU** | Paralel ortam + GPU = maksimum hÄ±z |
| **Backtest** (pandas iÅŸlemleri) | **CPU** | VektÃ¶rize pandas iÅŸlemleri |

---

## ğŸ“Š Performans KarÅŸÄ±laÅŸtÄ±rmasÄ±

### RTX 4060 8GB ile Beklenen HÄ±zlanma:

```
Technical Analysis (200+ indicators):
  CPU: ~0.5s per 10k bars âœ…
  GPU: ~0.5s per 10k bars (aynÄ±, Ã§Ã¼nkÃ¼ CPU zaten hÄ±zlÄ±)
  â¡ï¸ SonuÃ§: CPU kullan (kaynaklarÄ± GPU modellerine ayÄ±r)

XGBoost/LightGBM/CatBoost:
  CPU (12 cores): ~5s training âœ…
  GPU (RTX 4060): ~8s training (overhead yÃ¼zÃ¼nden yavaÅŸ)
  â¡ï¸ SonuÃ§: CPU kullan (kÃ¼Ã§Ã¼k-orta veri setleri iÃ§in)

LSTM Model (100 epochs):
  CPU: ~2000s (33 dakika) âŒ
  GPU (RTX 4060): ~80s (1.3 dakika) âœ…
  â¡ï¸ Speedup: 25x

Transformer Model (100 epochs):
  CPU: ~5000s (83 dakika) âŒ
  GPU (RTX 4060 + FP16): ~100s (1.7 dakika) âœ…
  â¡ï¸ Speedup: 50x

RL Training (100k timesteps):
  CPU: ~1200s (20 dakika) âŒ
  GPU (RTX 4060): ~120s (2 dakika) âœ…
  â¡ï¸ Speedup: 10x

Backtest (10k bars):
  CPU (vectorized): ~0.1s âœ…
  GPU: N/A (pandas operations)
  â¡ï¸ SonuÃ§: CPU kullan
```

---

## ğŸš€ KullanÄ±m Ã–rnekleri

### 1. Compute Manager BaÅŸlatma

```python
from backend.config.compute_config import initialize_compute, get_compute

# Hybrid mode (Ã–NERILIR)
compute = initialize_compute(mode='hybrid')

# Veya environment variable ile
# COMPUTE_MODE=hybrid python app.py
```

### 2. Ensemble ML Model (CPU)

```python
from backend.models.ensemble_model import EnsembleModel

# Otomatik olarak CPU kullanacak (hybrid modda)
model = EnsembleModel(task='regression')
model.fit(X_train, y_train, eval_set=(X_val, y_val))

# Ã‡Ä±ktÄ±:
# ğŸ–¥ï¸  Ensemble using CPU for tree models
#   XGBoost: hist
#   LightGBM: cpu
#   CatBoost: CPU
```

### 3. Deep Learning (GPU)

```python
from backend.models.deep_learning import DeepLearningTrainer

# Otomatik olarak GPU kullanacak (hybrid modda)
trainer = DeepLearningTrainer(model_type='lstm')
trainer.build_model(input_size=50, seq_len=60)
trainer.fit(X_train, y_train, X_val, y_val)

# Ã‡Ä±ktÄ±:
# ğŸš€ Deep Learning Trainer (LSTM)
#    Device: cuda
#    Batch Size: 128
#    Mixed Precision (FP16): True
```

### 4. RL Agent (GPU)

```python
from backend.models.rl_agent import RLAgent

env_config = {
    'df': market_data,
    'initial_balance': 100000.0,
    'lookback_window': 60,
}

# Otomatik olarak GPU kullanacak (hybrid modda)
agent = RLAgent(env_config, n_envs=8)
agent.train(total_timesteps=100000)

# Ã‡Ä±ktÄ±:
# ğŸ¤– RL Agent (PPO)
#    Device: CUDA
#    Parallel Environments: 8
```

### 5. Backtest Engine (CPU)

```python
from backend.backtest.backtest_engine import BacktestEngine, BacktestConfig

config = BacktestConfig(
    initial_capital=100000.0,
    commission=0.001,
    stop_loss=0.02,
)

# Otomatik olarak CPU kullanacak (hybrid modda)
engine = BacktestEngine(config)
results = engine.run(data, signals, strategy_name="My Strategy")

# Ã‡Ä±ktÄ±:
# ğŸ“Š Backtest Engine
#    Device: CPU
#    Parallel: True
#    Workers: All CPUs
```

---

## âš™ï¸ Compute Mode SeÃ§enekleri

### 1. HYBRID Mode (Ã–NERILIR)

```python
initialize_compute(mode='hybrid')
```

**Avantajlar:**
- En iyi performans
- Her iÅŸ tipi iÃ§in optimal cihaz
- GPU'yu yoÄŸun iÅŸler iÃ§in ayÄ±rÄ±r
- CPU'yu hafif iÅŸler iÃ§in kullanÄ±r

**RTX 4060 iÃ§in ideal!**

### 2. AUTO Mode

```python
initialize_compute(mode='auto')
```

**DavranÄ±ÅŸ:**
- GPU varsa â†’ HYBRID mode
- GPU yoksa â†’ CPU mode

### 3. CPU Mode

```python
initialize_compute(mode='cpu')
```

**KullanÄ±m durumlarÄ±:**
- GPU yoksa
- Test amaÃ§lÄ±
- GPU'yu baÅŸka iÅŸlere ayÄ±rmak istiyorsanÄ±z

### 4. GPU Mode

```python
initialize_compute(mode='gpu')
```

**Dikkat:** Tree-based modeller (XGBoost, CatBoost) CPU'da daha hÄ±zlÄ± olabilir!

**KullanÄ±m durumlarÄ±:**
- Sadece Deep Learning/RL kullanÄ±yorsanÄ±z
- BÃ¼yÃ¼k veri setleri (>1M samples)

---

## ğŸ§  Memory Optimization (RTX 4060 8GB)

### Mixed Precision (FP16)

Hybrid modda **otomatik aktif**:

```python
compute = get_compute()
print(compute.config.use_mixed_precision)  # True (GPU'da)
```

**FaydalarÄ±:**
- 2x daha az VRAM kullanÄ±mÄ±
- 1.5-2x daha hÄ±zlÄ± eÄŸitim
- RTX 4060 Tensor Core'larÄ± kullanÄ±r

### Batch Size Optimization

RTX 4060 8GB iÃ§in **otomatik optimize ediliyor**:

```python
compute = get_compute()
print(compute.config.dl_batch_size)  # 128 (RTX 4060 iÃ§in)
```

**VRAM'e gÃ¶re otomatik ayar:**
- 8GB+ VRAM â†’ Batch size 128
- 6-8GB VRAM â†’ Batch size 64
- <6GB VRAM â†’ Batch size 32

### Memory Cleanup

```python
compute = get_compute()
compute.optimize_memory()  # GPU cache'i temizle
```

**Otomatik Ã§alÄ±ÅŸÄ±r:**
- Model eÄŸitimi sonrasÄ±
- BÃ¼yÃ¼k iÅŸlem bitiminde

### Memory Statistics

```python
compute = get_compute()
stats = compute.get_memory_stats()

print(f"Total VRAM: {stats['total_gb']:.1f} GB")
print(f"Used VRAM: {stats['allocated_gb']:.1f} GB")
print(f"Free VRAM: {stats['free_gb']:.1f} GB")
print(f"Utilization: {stats['utilization_percent']:.1f}%")

# Ã–rnek Ã§Ä±ktÄ±:
# Total VRAM: 8.0 GB
# Used VRAM: 3.2 GB
# Free VRAM: 4.8 GB
# Utilization: 40.0%
```

---

## ğŸ”§ Environment Variables

`.env` dosyasÄ±na ekleyebilirsiniz:

```bash
# Compute mode
COMPUTE_MODE=hybrid  # hybrid, auto, cpu, gpu

# Logging
LOG_LEVEL=INFO
```

---

## ğŸ“ˆ RTX 4060 iÃ§in Best Practices

### âœ… YapÄ±lmasÄ± Gerekenler:

1. **Hybrid mode kullan** - En iyi performans
2. **Mixed precision aktif** - Otomatik (FP16)
3. **Batch size optimize** - Otomatik (128)
4. **Memory cleanup** - Otomatik
5. **Parallel environments (RL)** - 8 env optimal

### âŒ YapÄ±lmamasÄ± Gerekenler:

1. **Tree models GPU'da Ã§alÄ±ÅŸtÄ±rma** - CPU daha hÄ±zlÄ± (kÃ¼Ã§Ã¼k data)
2. **Ã‡ok bÃ¼yÃ¼k batch size** - VRAM taÅŸmasÄ±
3. **Multiple models aynÄ± anda GPU'da** - VRAM tÃ¼kenir
4. **Technical analysis GPU'da** - CPU zaten hÄ±zlÄ±

---

## ğŸ¯ Ã–rnek Workflow

### Tam Analiz Pipeline (Hybrid Mode)

```python
from backend.config.compute_config import initialize_compute
from backend.models.ensemble_model import EnsembleModel
from backend.models.deep_learning import DeepLearningTrainer
from backend.models.rl_agent import RLAgent
from backend.backtest.backtest_engine import BacktestEngine

# 1. Initialize compute
compute = initialize_compute(mode='hybrid')

# 2. Technical Analysis (CPU - pandas-ta)
# 200+ indicators calculated on CPU (fast)
indicators = calculate_indicators(data)  # ~0.5s for 10k bars

# 3. ML Ensemble (CPU - XGBoost, LightGBM, CatBoost)
# Tree models trained on CPU (faster for medium data)
ml_model = EnsembleModel()
ml_model.fit(X_train, y_train)  # ~5s training

# 4. Deep Learning (GPU - LSTM)
# LSTM trained on GPU with FP16 (50x faster)
dl_trainer = DeepLearningTrainer(model_type='lstm')
dl_trainer.build_model(input_size=50)
dl_trainer.fit(X_train, y_train, X_val, y_val)  # ~80s (vs 2000s CPU)

# 5. RL Training (GPU - PPO)
# RL agent trained on GPU (10x faster)
rl_agent = RLAgent(env_config, n_envs=8)
rl_agent.train(total_timesteps=100000)  # ~120s (vs 1200s CPU)

# 6. Backtest (CPU - vectorized pandas)
# Backtest runs on CPU (optimized for pandas)
engine = BacktestEngine()
results = engine.run(data, signals)  # ~0.1s for 10k bars

# Total time: ~210s (CPU-only: ~3600s)
# Speedup: 17x
```

---

## ğŸ“Š Performans Ä°zleme

### TensorBoard (Deep Learning)

```bash
tensorboard --logdir=./logs/tensorboard/
```

### GPU Monitoring

```bash
# Terminal 1: Training script
python train.py

# Terminal 2: GPU monitoring
nvidia-smi -l 1  # 1 saniye refresh
```

**Ä°deal RTX 4060 kullanÄ±mÄ±:**
- GPU Utilization: 90-100%
- Memory Usage: 60-80% (4-6GB/8GB)
- Temperature: <80Â°C
- Power: 80-100W (100W TDP)

---

## ğŸ†˜ Troubleshooting

### Problem 1: CUDA Out of Memory

**Ã‡Ã¶zÃ¼m:**
```python
# Batch size'Ä± azalt
trainer.config.batch_size = 64  # 128 yerine

# Veya model boyutunu kÃ¼Ã§Ã¼lt
model = LSTMModel(hidden_size=128)  # 256 yerine
```

### Problem 2: GPU kullanÄ±lmÄ±yor

**Kontrol:**
```python
import torch
print(torch.cuda.is_available())  # True olmalÄ±
print(torch.cuda.get_device_name(0))  # "NVIDIA GeForce RTX 4060 ..."
```

**Ã‡Ã¶zÃ¼m:**
- CUDA 13.0 kurulu mu kontrol et
- PyTorch GPU version mu kontrol et: `pip install torch --index-url https://download.pytorch.org/whl/cu121`

### Problem 3: YavaÅŸ eÄŸitim

**Kontrol:**
```python
compute = get_compute()
print(compute.config.use_mixed_precision)  # True olmalÄ±
print(compute.config.dl_batch_size)  # 128 olmalÄ± (RTX 4060)
```

---

## ğŸ“š Ä°leri Seviye

### Custom Device Selection

```python
from backend.config.compute_config import get_compute

compute = get_compute()

# Deep Learning iÃ§in GPU
dl_device = compute.get_torch_device('dl')  # cuda

# ML iÃ§in CPU
ml_device = compute.get_torch_device('ml')  # cpu

# XGBoost parametreleri
xgb_params = compute.get_xgboost_params()
# {'tree_method': 'hist', 'n_jobs': -1}

# CatBoost parametreleri
cat_params = compute.get_catboost_params()
# {'task_type': 'CPU', 'thread_count': None}
```

### Multiple GPU Support (gelecek)

Åu an tek GPU destekleniyor (RTX 4060). Multi-GPU desteÄŸi gelecek versiyonlarda eklenecek.

---

## ğŸ“ SonuÃ§

**RTX 4060 8GB iÃ§in en iyi yapÄ±landÄ±rma:**

```python
# .env
COMPUTE_MODE=hybrid

# Python
from backend.config.compute_config import initialize_compute
compute = initialize_compute(mode='hybrid')
```

**Bu yapÄ±landÄ±rma ile:**
- âœ… Technical Analysis â†’ CPU (hÄ±zlÄ±)
- âœ… ML Tree Models â†’ CPU (optimal)
- âœ… Deep Learning â†’ GPU + FP16 (25-50x hÄ±zlanma)
- âœ… RL Training â†’ GPU (10x hÄ±zlanma)
- âœ… Backtest â†’ CPU (vektÃ¶rize)

**Toplam performans artÄ±ÅŸÄ±:** 15-20x (CPU-only'ye gÃ¶re)

**VRAM kullanÄ±mÄ±:** 3-6GB (8GB iÃ§inde gÃ¼venli)

---

## ğŸ“ Destek

SorularÄ±nÄ±z iÃ§in:
- GitHub Issues
- DokÃ¼mantasyon: `/docs`
- Ã–rnekler: `/examples`
