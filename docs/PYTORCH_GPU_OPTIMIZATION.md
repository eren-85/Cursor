# PyTorch GPU Optimizasyon Rehberi

## ğŸš€ Ä°leri Seviye GPU AyarlarÄ±

Bu kÄ±lavuz PyTorch'un GPU performansÄ±nÄ± ve stabilitesini artÄ±rmak iÃ§in environment variable'lar ve en iyi pratikleri iÃ§erir.

---

## 1ï¸âƒ£ PYTORCH_CUDA_ALLOC_CONF (Memory Allocator)

### Nedir?

PyTorch'un CUDA memory allocator'Ä±nÄ±n davranÄ±ÅŸÄ±nÄ± kontrol eder.

### Tavsiye Edilen Ayar (RTX 4060 iÃ§in):

```powershell
# Windows PowerShell
$env:PYTORCH_CUDA_ALLOC_CONF = "expandable_segments:True,max_split_size_mb:128"

# Linux/Mac Bash
export PYTORCH_CUDA_ALLOC_CONF="expandable_segments:True,max_split_size_mb:128"

# Python iÃ§inde (script baÅŸÄ±nda)
import os
os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'expandable_segments:True,max_split_size_mb:128'
```

### Parametreler:

#### `expandable_segments:True`

**Ne yapar?**
- Memory segment'leri dinamik olarak geniÅŸletir
- Fragmentation'Ä± azaltÄ±r
- OOM (Out of Memory) riskini dÃ¼ÅŸÃ¼rÃ¼r

**Neden kullanmalÄ±?**
- âœ… Daha az memory fragmentation
- âœ… Daha iyi memory utilization
- âœ… OOM hatalarÄ±nÄ± Ã¶nler

**Trade-off:**
- âš ï¸ Ä°lk allocation biraz daha yavaÅŸ (~10ms)
- âœ… Ama training sÄ±rasÄ±nda Ã§ok daha stabil

#### `max_split_size_mb:128`

**Ne yapar?**
- Memory block'larÄ±nÄ±n maksimum split size'Ä± (MB)
- KÃ¼Ã§Ã¼k deÄŸer = daha az fragmentation
- BÃ¼yÃ¼k deÄŸer = daha az overhead

**128 MB neden ideal?**
- âœ… RTX 4060 8GB iÃ§in optimal
- âœ… Batch size 112-128 ile uyumlu
- âœ… Fragmentation vs overhead dengesi

**DiÄŸer deÄŸerler:**
```
max_split_size_mb:64   â†’ 6GB veya daha az VRAM iÃ§in
max_split_size_mb:128  â†’ 8GB VRAM iÃ§in (Ã–NERILIR)
max_split_size_mb:256  â†’ 12GB+ VRAM iÃ§in
max_split_size_mb:512  â†’ 24GB+ VRAM iÃ§in
```

---

## 2ï¸âƒ£ KalÄ±cÄ± Ayar (Windows)

### PowerShell Profile (.ps1):

```powershell
# PowerShell profilinizi aÃ§Ä±n
notepad $PROFILE

# Ekleyin:
$env:PYTORCH_CUDA_ALLOC_CONF = "expandable_segments:True,max_split_size_mb:128"

# Kaydedin ve yeni terminal aÃ§Ä±n
```

### System Environment Variables:

1. Windows Arama â†’ "Environment Variables"
2. "New" â†’ Variable name: `PYTORCH_CUDA_ALLOC_CONF`
3. Variable value: `expandable_segments:True,max_split_size_mb:128`
4. OK â†’ Terminali yeniden baÅŸlat

---

## 3ï¸âƒ£ DiÄŸer FaydalÄ± Environment Variables

### CUDA_LAUNCH_BLOCKING (Debug iÃ§in)

```powershell
# Asynchronous CUDA operations'Ä± senkron yapar
# Sadece DEBUG iÃ§in kullan (yavaÅŸlatÄ±r!)
$env:CUDA_LAUNCH_BLOCKING = "1"
```

**Ne zaman kullanÄ±lÄ±r:**
- âŒ Training sÄ±rasÄ±nda KULLANMA (Ã§ok yavaÅŸ)
- âœ… Error debug ederken kullan
- âœ… Hangi operation'da OOM olduÄŸunu bulmak iÃ§in

### PYTORCH_NO_CUDA_MEMORY_CACHING (Debug iÃ§in)

```powershell
# Memory caching'i devre dÄ±ÅŸÄ± bÄ±rakÄ±r
# Sadece DEBUG iÃ§in!
$env:PYTORCH_NO_CUDA_MEMORY_CACHING = "1"
```

**Ne zaman kullanÄ±lÄ±r:**
- âŒ Asla normal training'de kullanma
- âœ… Memory leak debug iÃ§in

---

## 4ï¸âƒ£ DataLoader OptimizasyonlarÄ± (Windows)

### Tavsiye Edilen Ayarlar:

```python
from torch.utils.data import DataLoader

loader = DataLoader(
    dataset,
    batch_size=112,  # RTX 4060 iÃ§in optimal
    num_workers=2,   # Windows iÃ§in 2-4 (spawn overhead)
    pin_memory=True, # GPU iÃ§in MUTLAKA True
    persistent_workers=True,  # Workers'Ä± cache'le (daha hÄ±zlÄ±)
)
```

### Parametreler:

#### `num_workers` (Windows iÃ§in)

**Optimal deÄŸer: 2-4**

```python
# Windows spawn maliyeti yÃ¼ksek
num_workers=0  # âŒ YavaÅŸ (main process'te load)
num_workers=2  # âœ… Ä°yi (2 parallel worker)
num_workers=4  # âœ… Optimal (4 parallel worker)
num_workers=8  # âš ï¸ Overhead fazla (diminishing returns)
```

**Neden 2-4?**
- Windows multiprocessing `spawn` kullanÄ±r (Linux `fork` kullanÄ±r)
- Spawn daha yavaÅŸ (her worker full process copy)
- 4'ten fazla worker â†’ overhead > benefit

#### `pin_memory=True` (GPU iÃ§in MUTLAKA)

**Ne yapar?**
- CPU memory'yi pinned (page-locked) yapar
- GPU transfer 2-3x daha hÄ±zlÄ±
- Ã–zellikle bÃ¼yÃ¼k batch'lerde kritik

**Neden True olmalÄ±?**
```python
pin_memory=False:
  CPU â†’ GPU transfer: ~2.5 GB/s âŒ

pin_memory=True:
  CPU â†’ GPU transfer: ~6-8 GB/s âœ… (2.5x faster)
```

#### `persistent_workers=True` (PyTorch 1.7+)

**Ne yapar?**
- Worker process'leri epoch arasÄ± cache'ler
- Her epoch'ta worker spawn etmez
- Windows'ta Ã¶zellikle faydalÄ± (spawn maliyeti)

**Performans:**
```python
persistent_workers=False:
  Epoch 1: 65s (worker spawn dahil)
  Epoch 2: 65s (worker spawn dahil) âŒ

persistent_workers=True:
  Epoch 1: 65s (ilk spawn)
  Epoch 2: 60s (spawn yok) âœ…
```

---

## 5ï¸âƒ£ Memory Cleanup Best Practices

### Training Loop Ä°Ã§inde:

```python
from backend.config.compute_config import get_compute

compute = get_compute()

# Training loop
for epoch in range(num_epochs):
    # Epoch baÅŸÄ±nda peak stats reset
    compute.reset_peak_memory_stats()

    # Training...
    for batch in train_loader:
        # Forward/backward
        loss.backward()
        optimizer.step()

    # Epoch sonunda cleanup
    compute.cleanup_after_training()

    # Memory stats log
    if epoch % 10 == 0:
        compute.log_memory_stats()
```

### Model Switching:

```python
# Model 1 training
model1.train()
# ...

# Model deÄŸiÅŸtirmeden Ã¶nce cleanup
del model1
compute.cleanup_after_training()

# Model 2 training
model2 = MyModel().to(device)
```

### Large Operation SonrasÄ±:

```python
# BÃ¼yÃ¼k tensor iÅŸlemi
large_output = model(large_input)

# Ä°ÅŸlem bittikten sonra cleanup
del large_output
compute.optimize_memory(aggressive=True)
```

---

## 6ï¸âƒ£ Performans Monitoring

### VRAM KullanÄ±mÄ±nÄ± Ä°zle:

```python
compute = get_compute()

# AnlÄ±k kullanÄ±m
used, reserved = compute.vram_usage_gib()
print(f"Used: {used} GiB, Reserved: {reserved} GiB")

# DetaylÄ± stats
stats = compute.get_memory_stats()
print(f"Utilization: {stats['utilization_percent']}%")
print(f"Peak: {stats['max_allocated_gib']} GiB")
```

### nvidia-smi ile Real-time Monitoring:

```powershell
# Terminal 1: Training
python train.py

# Terminal 2: Monitoring (1 saniye refresh)
nvidia-smi -l 1
```

**Ä°deal kullanÄ±m (RTX 4060 8GB):**
```
GPU Utilization: 90-100%  âœ…
Memory Usage: 6-7.5 GiB   âœ… (margin var)
Temperature: <80Â°C        âœ…
Power: 80-100W            âœ…
```

---

## 7ï¸âƒ£ Troubleshooting

### OOM (Out of Memory) HatasÄ±

**Ã‡Ã¶zÃ¼mler (Ã¶ncelik sÄ±rasÄ±yla):**

1. **Batch size azalt:**
   ```python
   batch_size = compute.suggest_batch_size(vram_usage_multiplier=0.75)
   ```

2. **Gradient accumulation kullan:**
   ```python
   accumulation_steps = 2
   effective_batch_size = batch_size * accumulation_steps
   ```

3. **Mixed precision kullan (zaten aktif):**
   ```python
   # BF16 zaten aktif
   # EÄŸer FP32 kullanÄ±yorsan â†’ BF16'ya geÃ§
   ```

4. **Memory allocator ayarla:**
   ```powershell
   $env:PYTORCH_CUDA_ALLOC_CONF = "expandable_segments:True,max_split_size_mb:64"
   ```

### YavaÅŸ Data Loading

**Ã‡Ã¶zÃ¼mler:**

1. **num_workers artÄ±r:**
   ```python
   num_workers=4  # 2'den 4'e Ã§Ä±kar
   ```

2. **persistent_workers kullan:**
   ```python
   persistent_workers=True
   ```

3. **pin_memory aktif mi kontrol et:**
   ```python
   pin_memory=True  # GPU iÃ§in mutlaka
   ```

### Fragmentation

**Ã‡Ã¶zÃ¼m:**
```powershell
$env:PYTORCH_CUDA_ALLOC_CONF = "expandable_segments:True,max_split_size_mb:128"
```

---

## 8ï¸âƒ£ Ã–zet: RTX 4060 iÃ§in Optimal Ayarlar

### Environment Variables (.ps1 profile):

```powershell
# Memory allocator
$env:PYTORCH_CUDA_ALLOC_CONF = "expandable_segments:True,max_split_size_mb:128"
```

### Python Config:

```python
from backend.config.compute_config import get_compute, initialize_compute

# Hybrid mode baÅŸlat
compute = initialize_compute(mode='hybrid')

# DataLoader ayarlarÄ±
loader = DataLoader(
    dataset,
    batch_size=112,           # RTX 4060 iÃ§in gÃ¼venli
    num_workers=2,            # Windows optimal
    pin_memory=True,          # GPU transfer hÄ±zÄ±
    persistent_workers=True,  # Worker cache
)

# Training loop
for epoch in range(epochs):
    compute.reset_peak_memory_stats()

    # Training...

    compute.cleanup_after_training()
```

### Beklenen Performans:

```
VRAM: 7-7.5 GiB / 8 GiB (margin: 0.5-1 GiB) âœ…
GPU Util: 90-100%                          âœ…
Throughput: ~780 samples/sec (batch 112)   âœ…
OOM Risk: <5%                              âœ…
```

---

## ğŸ“š Referanslar

- [PyTorch CUDA Semantics](https://pytorch.org/docs/stable/notes/cuda.html)
- [PyTorch DataLoader](https://pytorch.org/docs/stable/data.html)
- [CUDA Memory Management](https://pytorch.org/docs/stable/notes/cuda.html#memory-management)

---

**Notlar:**
- Bu ayarlar RTX 4060 8GB iÃ§in optimize edilmiÅŸtir
- FarklÄ± GPU'lar iÃ§in parametreleri ayarlayÄ±n
- Production'da her zaman test edin
